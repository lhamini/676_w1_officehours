{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.espn.com/', 'title': 'ESPN - Serving Sports Fans. Anytime. Anywhere.', 'description': 'Visit ESPN for live scores, highlights and sports news. Stream exclusive games on ESPN+ and play fantasy sports.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\nESPN - Serving Sports Fans. Anytime. Anywhere.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Skip to main content\\n    \\n\\n        Skip to navigation\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n<\\n\\n>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMenuESPN\\n\\n\\n\\n\\n\\nscores\\n\\n\\n\\n\\nNEW! Find where to watch all of your favorite sports!\\n\\n\\n\\n\\n\\n\\n\\nNFLNBAMLBNCAAFNHLSoccerWNBAMore SportsBoxingCFLNCAACricketF1GolfHorseLLWSMMANASCARNBA G LeagueNBA Summer LeagueNCAAMNCAAWNWSLOlympicsPLLProfessional WrestlingRacingRN BBRN FBRugbySports BettingTennisX GamesUFLFantasyWatchESPN BETESPN+\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\nSubscribe Now\\n\\n\\n\\n\\n\\nLALIGA\\n\\n\\n\\n\\n\\n\\n\\nMLB\\n\\n\\n\\n\\n\\n\\n\\nNCAA Women\\'s Volleyball\\n\\n\\n\\n\\n\\n\\n\\nNHL: Preseason\\n\\n\\n\\n\\n\\n\\n\\nNFL Turning Point\\n\\n\\n\\n\\n\\n\\n\\nUFC 307: Pereira vs. Rountree Jr. (Oct. 5, ESPN+ PPV)\\n\\n\\nQuick Links\\n\\n\\n\\n\\nWhere To Watch\\n\\n\\n\\n\\n\\n\\n\\nWNBA Playoffs\\n\\n\\n\\n\\n\\n\\n\\nMLB Playoff Tracker\\n\\n\\n\\n\\n\\n\\n\\nMLB Standings\\n\\n\\n\\n\\n\\n\\n\\n2024 NFL Schedule\\n\\n\\n\\n\\n\\n\\n\\nCollege Football Schedule\\n\\n\\n\\n\\n\\n\\n\\nESPN Radio: Listen Live\\n\\n\\n\\n\\n\\n\\nFavorites\\n\\n\\n\\n\\n\\n\\n      Manage Favorites\\n      \\n\\n\\n\\nCustomize ESPNCreate AccountLog InFantasy\\n\\n\\n\\n\\nFootball\\n\\n\\n\\n\\n\\n\\n\\nBaseball\\n\\n\\n\\n\\n\\n\\n\\nBasketball\\n\\n\\n\\n\\n\\n\\n\\nHockey\\n\\n\\nESPN Sites\\n\\n\\n\\n\\nESPN Deportes\\n\\n\\n\\n\\n\\n\\n\\nAndscape\\n\\n\\n\\n\\n\\n\\n\\nespnW\\n\\n\\n\\n\\n\\n\\n\\nESPNFC\\n\\n\\n\\n\\n\\n\\n\\nX Games\\n\\n\\n\\n\\n\\n\\n\\nSEC Network\\n\\n\\nESPN Apps\\n\\n\\n\\n\\nESPN\\n\\n\\n\\n\\n\\n\\n\\nESPN Fantasy\\n\\n\\n\\n\\n\\n\\n\\nTournament Challenge\\n\\n\\nFollow ESPN\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\n\\n\\nX/Twitter\\n\\n\\n\\n\\n\\n\\n\\nInstagram\\n\\n\\n\\n\\n\\n\\n\\nSnapchat\\n\\n\\n\\n\\n\\n\\n\\nTikTok\\n\\n\\n\\n\\n\\n\\n\\nYouTube\\n\\n\\n\\'Evolve or die\\': Kirby Smart is already on his way out of Saban’s shadow9hChris LowTOP HEADLINESFranco ordered to stand trial in sexual abuse caseLawsuit filed over ownership of Ohtani 50/50 ballUFC agrees to $375M settlement in antitrust suitSark still unsure on starting QB for SEC debutEx-MVP Rose retiring after 16-year NBA careerDucks flip five-star lineman Utu from TennesseeRicciardo gets F1 send-off, replaced by LawsonLeafs\\' Matthews dealing with upper-body injuryBold predictions for all 32 NHL teamsCONTENDERS OR PRETENDERS?Which undefeated NFL team is due for a reality check? Barnwell sorts through all fiveLet\\'s evaluate every undefeated team  and how they\\'ve won three straight games. Is what they\\'re doing sustainable?9hBill BarnwellAP Photo/Matt FreedMLB SCOREBOARDTHURSDAY\\'S GAMESSee AllStandingsPlayoff trackerIN THE HOMESTRETCHMLB insiders predict the playoffs: Fiery takes, dangerous teams, breakout starsThe 2024 postseason seems wide open. Here\\'s who scouts and execs think could decide October.9hMLB InsidersTroy Taormina-Imagn ImagesPGA TOUR: PRESIDENTS CUPTHROUGH SUNDAYSee All\\'What was that?!\\' Scottie Scheffler yells at Tom Kim after birdie putt57m0:53Biggest strengths, weaknesses and who will winGiants\\' Daniel Jones: \\'I\\'ve played more, seen more, studied and improved\\' -- but is it enough?This Daniel Jones is bigger, stronger -- but has more calluses -- unlike his former rookie self who was once the Giants\\' \"next great quarterback.\"10hJordan RaananNic Antaya/Getty ImagesStephen A. to Cowboys: You\\'re trash if you can\\'t beat the Giants4h1:49Trevon Diggs\\' yearlong journey to prove he\\'s still eliteBetting tips for Cowboys-GiantsHOW THEY STACK UPRanking all 32 NFL backup quarterbacks: Drew Lock? Jameis Winston? Michael Penix Jr.? Russell Wilson?!The No. 2 quarterback is an underrated part of an NFL roster. So how do Drew Lock, Jameis Winston, Tyrod Taylor and Kenny Pickett stack up?9hSeth WalderVincent Carchietta-USA TODAY SportsWHAT\\'S NEXT?WNBA offseason guides for every eliminated team: What\\'s next for Caitlin Clark, Fever?What are the offseason priorities and needs for every WNBA team? We break it down as each team is eliminated from the playoff race.16hESPNAP Photo/Jessica HillStephen A., Chiney Ogwumike debate level of Clark\\'s impact on WNBA5h2:25Season over, Clark sees \\'what\\'s possible\\' for FeverPROJECTING THE 2024-25 SEASONTimberwolves tumble? Nets to the play-in? Win projections for all 30 NBA teamsESPN NBA insider Kevin Pelton unveils his annual win projections for all 30 teams. Where does your team land?7hKevin PeltonAlonzo Adams-USA TODAY Sports Top HeadlinesFranco ordered to stand trial in sexual abuse caseLawsuit filed over ownership of Ohtani 50/50 ballUFC agrees to $375M settlement in antitrust suitSark still unsure on starting QB for SEC debutEx-MVP Rose retiring after 16-year NBA careerDucks flip five-star lineman Utu from TennesseeRicciardo gets F1 send-off, replaced by LawsonLeafs\\' Matthews dealing with upper-body injuryBold predictions for all 32 NHL teamsFavorites FantasyManage FavoritesFantasy HomeCustomize ESPNCreate AccountLog InICYMI1:05Padres turn game-ending triple play to clinch a playoff spotThe Padres stun the Dodgers in dramatic fashion, turning an ultra-rare, game-ending triple play to clinch a spot in the playoffs. Best of ESPN+Matthew O\\'Haren-USA TODAY SportsThese college football coaches could be next in line for big jobsThe college football coaching carousel isn\\'t moving yet, but these are the coaches to watch for the next big job opening.AP Photo/Bruce KluckhohnNFL quarterback heat check: Sizing up Fields, Darnold, DaltonCan Sam Darnold, Justin Fields and Andy Dalton really keep winning? Plus, could the 3-0 Seahawks take the NFC West?Gary A. Vasquez-USA TODAY SportsPredicting six NBA teams to improve or decline in the 2024-25 seasonWhich NBA teams will rise and which will fall in the standings? Predicting the outlook of six teams.Ben Whitley/PA Images via Getty ImagesTrue or False: Early Premier League trends analyzedCan Arsenal win ugly now? Will Ryan Gravenberch fill Liverpool\\'s DM slot? Is Jhon Durán or Nicolas Jackson the next great striker? Let\\'s answer those early Premier League questions. Trending NowMichael Wade/Getty ImagesFormer Georgia, Alabama football coach Scott Cochran\\'s new life after addictionScott Cochran was a rising star coach at Alabama and then Georgia while hiding what he calls an addiction to painkillers. He is now sober and is out of coaching, trying to help others going through similar struggles.AP Photo/Jessica HillWNBA offseason 2024: Guides for every WNBA teamWhat are the offseason priorities and needs for every WNBA team? We break it down as each team is eliminated from the playoff race.ESPN Illustration2024 MLB playoff picture: Schedule, bracket, clinching scenarios\\n\\nWe have everything you need to know as the regular season reaches the homestretch, from current playoff matchups to league races to the postseason schedule.Illustration by ESPNThreatened with jail over a scandal headlined by Brett FavreAfter exposing Mississippi welfare fraud, a journalist and her publication face the former governor\\'s wrath. Sign up to play the #1 Fantasy game!Create A LeagueJoin Public LeagueReactivate A LeagueMock Draft NowSign up for FREE!Create A LeagueJoin a Public LeagueReactivate a LeaguePractice With a Mock DraftSign up for FREE!Create A LeagueJoin a Public LeagueReactivate a LeaguePractice with a Mock DraftGet a custom ESPN experienceEnjoy the benefits of a personalized accountSelect your favorite leagues, teams and players and get the latest scores, news and updates that matter most to you. \\n\\nESPN+\\n\\n\\n\\n\\nWatch Now\\n\\n\\n\\n\\n\\n\\n\\nLALIGA\\n\\n\\n\\n\\n\\n\\n\\nMLB\\n\\n\\n\\n\\n\\n\\n\\nNCAA Women\\'s Volleyball\\n\\n\\n\\n\\n\\n\\n\\nNHL: Preseason\\n\\n\\n\\n\\n\\n\\n\\nNFL Turning Point\\n\\n\\n\\n\\n\\n\\n\\nUFC 307: Pereira vs. Rountree Jr. (Oct. 5, ESPN+ PPV)\\n\\n\\nQuick Links\\n\\n\\n\\n\\nWhere To Watch\\n\\n\\n\\n\\n\\n\\n\\nWNBA Playoffs\\n\\n\\n\\n\\n\\n\\n\\nMLB Playoff Tracker\\n\\n\\n\\n\\n\\n\\n\\nMLB Standings\\n\\n\\n\\n\\n\\n\\n\\n2024 NFL Schedule\\n\\n\\n\\n\\n\\n\\n\\nCollege Football Schedule\\n\\n\\n\\n\\n\\n\\n\\nESPN Radio: Listen Live\\n\\n\\nFantasy\\n\\n\\n\\n\\nFootball\\n\\n\\n\\n\\n\\n\\n\\nBaseball\\n\\n\\n\\n\\n\\n\\n\\nBasketball\\n\\n\\n\\n\\n\\n\\n\\nHockey\\n\\n\\nESPN Sites\\n\\n\\n\\n\\nESPN Deportes\\n\\n\\n\\n\\n\\n\\n\\nAndscape\\n\\n\\n\\n\\n\\n\\n\\nespnW\\n\\n\\n\\n\\n\\n\\n\\nESPNFC\\n\\n\\n\\n\\n\\n\\n\\nX Games\\n\\n\\n\\n\\n\\n\\n\\nSEC Network\\n\\n\\nESPN Apps\\n\\n\\n\\n\\nESPN\\n\\n\\n\\n\\n\\n\\n\\nESPN Fantasy\\n\\n\\n\\n\\n\\n\\n\\nTournament Challenge\\n\\n\\nFollow ESPN\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\n\\n\\nX/Twitter\\n\\n\\n\\n\\n\\n\\n\\nInstagram\\n\\n\\n\\n\\n\\n\\n\\nSnapchat\\n\\n\\n\\n\\n\\n\\n\\nTikTok\\n\\n\\n\\n\\n\\n\\n\\nYouTube\\n\\n\\nTerms of UsePrivacy PolicyYour US State Privacy RightsChildren\\'s Online Privacy PolicyInterest-Based AdsAbout Nielsen MeasurementDo Not Sell or Share My Personal InformationContact UsDisney Ad Sales SiteWork for ESPNCorrectionsESPN BET is owned and operated by PENN Entertainment, Inc. and its subsidiaries (\\'PENN\\'). ESPN BET is available in states where PENN is licensed to offer sports wagering. Must be 21+ to wager. If you or someone you know has a gambling problem and wants help, call 1-800-GAMBLER.Copyright: © 2024 ESPN Enterprises, Inc. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.espn.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "\n",
    "MYURL = \"https://www.youtube.com/watch?v=0iznczNq0UQ\"\n",
    "loader = YoutubeLoader.from_youtube_url(MYURL) \n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = docs[0].page_content \n",
    "metadata = docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so Meta has added some new\n",
      "models to the Llama herd of models. And if we go back to when the\n",
      "original Llama 3 was released, a lot of people at that stage were\n",
      "actually expecting that the Llama 3 models were going to be multimodal. That's what quite a few rumors had\n",
      "talked about, and it made sense that a lot of other models, even\n",
      "some open source models, were going for the multimodal approach. but unfortunately back then we\n",
      "didn't get the multimodal models. Today we have been given\n",
      "the multimodal models. So Llama 3.2 adds four new models. And it really seems to be a strategic\n",
      "release where they're covering what they didn't have in the herd already. we've got two multimodal models,\n",
      "which are basically just VLMs. So vision language models. And we've got two very small Llama models\n",
      "that are built for on device stuff. So let's jump in and have a look\n",
      "at what they actually announced. So we can see that they've got the four\n",
      "models, starting out with the new Vision LLMs, and they're calling the small\n",
      "one of these the 11 billion model and a medium sized 90 billion model, which is\n",
      "a really interesting size that we haven't seen for open source models in the past. And then they've also released these\n",
      "two lightweight text only models. So this is a 1 billion\n",
      "and a 3 billion model. And the whole idea around these ones\n",
      "is that they are basically made to fit on phones, on mobile devices,\n",
      "on a Raspberry Pi, etc in there. so all of the models basically\n",
      "have instruction tuned versions coming with them. The text only models go out to\n",
      "128K and they talk about these being state of the art for their\n",
      "class, for on device use cases. I'll look at some of the stats later\n",
      "on about the models and comment a little bit about where the models\n",
      "are strong and perhaps where Meta hasn't been totally transparent with\n",
      "what they've declared and compared against, in their evaluations out here. But it certainly is nice to have\n",
      "these 1 billion and 3 billion models. I'll show you later on, you can\n",
      "already run these in Ollama. They're very quick and snappy,\n",
      "and it makes a lot of sense that these would be things that, you\n",
      "would want on, a mobile device. So we know that the new models that\n",
      "are coming with Apple Intelligence are around about the three billion range. We know that Google has the\n",
      "Gemini Nano models, which are in a similar size to this. We know that, companies like Qwen have\n",
      "put out some, models that are this size and some actually even smaller. But basically, we know that this is the\n",
      "right sort of size model at the moment for a mobile phone, that while you can\n",
      "run the 7, 8 billion models on devices, you need quite a bit of RAM, and they\n",
      "just don't tend to run that quick. you can certainly imagine having one of\n",
      "these fast models with 128k token window, being able to summarize conversations\n",
      "in chat, read emails for you, do a whole bunch of, small but very useful things,\n",
      "that you could want on a mobile phone. it's also interesting that\n",
      "they've optimized these for certain kinds of hardware. On the other end of what Meta has\n",
      "released are the vision models. So these are definitely a lot bigger. We've got an 11 billion\n",
      "model, a 90 billion model. like I mentioned before, the\n",
      "90 billion is a strange size. We haven't seen that. Normally vision encoders\n",
      "are not hugely big. So I'm not sure if this is basically\n",
      "a bigger LLM with a vision coder or a much bigger Vision encoder compared to\n",
      "what other people are using out there. But they talk about that these are\n",
      "basically drop in replacements for corresponding text model equivalents. and you certainly can imagine that\n",
      "these are going to become very popular for doing fine tunes and stuff like\n",
      "that, just like all the Llama models. So if we look at the model evaluation\n",
      "starting with these vision models, we can see that they're claiming\n",
      "that, okay, the 90 billion here is performing better than the GPT 4. 0 mini. And that even the 11 billion is\n",
      "performing better than Claude III Haiku. Remember that Haiku is the\n",
      "smallest model from Anthropic. Certainly not the one that probably\n",
      "people would be using for doing really high, any sort of high end vision stuff. Now, one of the things that I feel\n",
      "they're not being totally transparent here is that they haven't compared\n",
      "or benchmarked against the Qwen2 VL model, the 72 billion version of that. If we come and look at that, they're\n",
      "actually benchmarking against Claude 3. 5 Sonnet for their vision capabilities\n",
      "and GPT 4o, not 4o Mini in here. So if we look at this\n",
      "MMMU, they're getting 64. 5, which is quite a lot more than\n",
      "any of these models, are getting. and if you compare some of the\n",
      "other stats too, you can see that They're also performing really\n",
      "well with a smaller model, right? Just a 70 billion model as opposed\n",
      "to a 90 billion model in here. Now that said, the Qwen2 VL model\n",
      "hasn't been out a huge amount of time, So perhaps in some ways they scooped\n",
      "Meta's announcement a little bit here. As with all LLMs these days though,\n",
      "you really want to try out each of the models and see for your particular\n",
      "use case how it's going to perform. You may find that for your use\n",
      "case the Llama 3.2 is going to be better for your use case. Following up on the vision benchmarks,\n",
      "we've got the benchmarks for the lightweight 1B and 3B models. And these certainly look, impressive. They're comparing it to Gemma 2, Which in some ways surprisingly\n",
      "has become a very popular model. Last month I was in Beijing and\n",
      "talking to developers there. I was surprised how many of them were\n",
      "using the Gemma 2 2B models for mobile and stuff like that, even though it had only\n",
      "been out a couple of weeks at that time. And they were using it for a variety\n",
      "of different use cases, where they're basically fine tuning it for things like\n",
      "chat, summarization, a whole bunch of different things like that So, that's\n",
      "going to be very interesting to look at. Now, the other model that they compare\n",
      "to in here is the Phi 3.5 Mini, which is one of my favorite models at this point. And, I've got to say that, start off,\n",
      "their models are actually quite a bit smaller than the Phi 3.5  when\n",
      "you're looking at a 3B versus a 3. 8 billion model, the other thing here\n",
      "is that it's strange that, the Phi 3.5 does really well with GSM 8K. And the Llama 3.2 is not even close there. Yet, for the math dataset, which you\n",
      "would consider to be harder than GSM 8K, they're beating the Phi 3.5 mini here. Again, this is where I find the\n",
      "whole issue around benchmarks more and more frustrating day\n",
      "by day as we go through this. And I really feel like at the end of the\n",
      "day, you have to trust a few providers that are putting out these models,\n",
      "try them out for your particular use case, and then see, how they go there. So one of the things that really is\n",
      "interesting, around the lightweight models is actually how they've created these. So these are sort of culled down\n",
      "versions of the Llama 3.1 8B  in that what they've done is they've\n",
      "basically pruned the model and then they've done knowledge distillation\n",
      "from the 8B and the 70B models. So this is something that's really\n",
      "interesting, the whole concept of making these models, smaller or\n",
      "smaller versions of these models where they're not training from scratch. they're basically taking the pre\n",
      "trained versions, pruning them out, so removing a lot of stuff from them, and\n",
      "then fixing them up with knowledge. Pruning them out where they're\n",
      "removing, a lot of weights and probably even some layers, from them. obviously they're working out\n",
      "which are the best ones to remove and stuff like that. then they're doing the actual knowledge\n",
      "distillation where they're taking these, Llama 3.1 8B and 70B and\n",
      "taking the logits layer out of those. So rather than just doing distillation\n",
      "where you're predicting on what was the best sequence, you're actually\n",
      "here looking at, trying to predict the exact same probabilities across the\n",
      "softmax layer as you go through this. So this has always been a very\n",
      "nice way to do this kind of, going from a big model to a small model. It's something that works very well. once they've done this, they then go\n",
      "to a sort of more traditional post training where they're basically\n",
      "doing fine tuning, rejection sampling and DPO for alignment in there. and if we go back to the Llama 3. 1 paper, we can see exactly how they're\n",
      "doing this, because It's the same sort of thing as what they did on the Llama 3. 1, fine tunes for the\n",
      "instruction tunes, etc. so along with the models themselves,\n",
      "Meta has also released some nice demos that we can see here for doing things\n",
      "like summarization, rewriting, etc. and another interesting, thing which\n",
      "probably deserves its own video by itself, let it run as I start to play\n",
      "with this a lot more, is that they've released these sort of Llama Stack APIs. and clearly they can see that the\n",
      "future is going to be agentic apps. You can see this, what\n",
      "they're talking about here. And they're setting up to basically\n",
      "have a stack of where you can run all of these things, together, whether that's\n",
      "going to be, on device for a phone or whether that's going to be in the cloud. And I think this could end up being\n",
      "one of the really interesting things, that comes out of this release as\n",
      "we start to play with some of these things and see how they're thinking\n",
      "about using these, because don't forget behind Meta, we've got the whole\n",
      "juggernaut that is Facebook that wants to run these models in their apps and\n",
      "do the whole sort of Meta AI thing. So the models are out. You can basically come in here\n",
      "to Hugging Face and if you opt in you will be able to get access. So there are gated access\n",
      "and stuff like that. But once you've opted in, You can\n",
      "try the models out and you can see that, again, we've got a whole bunch\n",
      "of interesting things that are coming with these models, with the Llama\n",
      "Guard as well as, the traditional instruct and base models in here. I think you're going to see these\n",
      "models pop up in a whole bunch of places over the next week or so. let's jump in and have a look at using\n",
      "this in Ollama, and just see what speeds we get with these smaller text models. Okay. So if we jump into Ollama here, I've\n",
      "basically pulled down the 3 billion texts model and the 1 billion text model. if we run the 3 billion text model. I'm not running it on a\n",
      "super-fast machine here. This is a Mac mini. you're going to see that, it is\n",
      "actually pretty snappy in how it's, writing, the texts and stuff like that. and also, if we set it too\n",
      "verbose, we can then actually come and see the tokens per second. That's actually generating out here. And can see that we're getting 47 tokens\n",
      "per second on this particular generation. Earlier on, I was getting\n",
      "often 55 tokens per second out. which is very fast, right? When you're thinking that,\n",
      "most people read at only a few hundred words per minute. and here, we're able to generate\n",
      "out 50 plus tokens per second. that's certainly good. but really, of course, what, the main\n",
      "reason we want, this is not necessarily for people to read it really fast,\n",
      "but for agents to be able to use this. Okay. Trying the same thing with the 1\n",
      "billion model, you can see that this is really playing here. and while obviously the quality,\n",
      "is going to go down for this. It's probably not the kind of\n",
      "model I would use for doing writing tasks and stuff like that. This is definitely a nice snappy model. we're getting around 80 plus\n",
      "tokens per second there. This is certainly a model that you could\n",
      "use for a bunch of little different things of doing some summarization. Doing some simple extraction,\n",
      "that kind of thing. I haven't checked to see\n",
      "how well these things handle JSON and stuff like that yet. I'm not expecting that you'd\n",
      "really want to use this for doing function calling too much, unless\n",
      "you're going to be fine tuning for specific tools, that kind of thing. The cool thing though, is when\n",
      "this model is so small, fine tuning it just becomes so easy as well. So perhaps that's something that we can\n",
      "look at in a future video is fine tuning these for some simple tasks, and stuff. Anyway, just to finish up. This is definitely an\n",
      "interesting release from Meta. the models are all up. You can go and play with them. You can try these things out yourself. I do think we're going to see these models\n",
      "pop up on people's phones pretty quickly. And certainly people will be fine\n",
      "tuning them for various kind of uses Like chatbots and things like that. And then we've got the multimodal\n",
      "models, which Meta has been really good at a lot of vision models in the past. Things like, the SAM2 model, et cetera. I made a video on. in many ways, this is, the Llama\n",
      "team's First sort of dip into doing these multimodal, models. And perhaps we will see,\n",
      "even more modalities come out over the next few months. After having recently done a video about\n",
      "Moshi and stuff like that, you could imagine some really nice combinations of putting in audio model and training\n",
      "and adapter for that to go into a Llama model, which would be really cool as well. Anyway, as always, if you've got\n",
      "any questions or comments, please put them in the comments below. if you found the video useful,\n",
      "please click like and subscribe. And I will talk to you in the next video. Bye for now.\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '0iznczNq0UQ'}\n"
     ]
    }
   ],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(MYURL, add_video_info=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '0iznczNq0UQ', 'title': 'Llama 3.2 goes Multimodal and to the Edge', 'description': 'Unknown', 'view_count': 2047, 'thumbnail_url': 'https://i.ytimg.com/vi/0iznczNq0UQ/hq720.jpg', 'publish_date': '2024-09-26 00:00:00', 'length': 789, 'author': 'Sam Witteveen'}\n"
     ]
    }
   ],
   "source": [
    "metadata = docs[0].metadata\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 0iznczNq0UQ\n",
      "title: Llama 3.2 goes Multimodal and to the Edge\n",
      "description: Unknown\n",
      "view_count: 2047\n",
      "thumbnail_url: https://i.ytimg.com/vi/0iznczNq0UQ/hq720.jpg\n",
      "publish_date: 2024-09-26 00:00:00\n",
      "length: 789\n",
      "author: Sam Witteveen\n"
     ]
    }
   ],
   "source": [
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2\", temperature=0\n",
    ")  \n",
    "\n",
    "print(llm.invoke(\"Hi, Who are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about a person named Sam Witteveen or a topic called \"llama3.2\". Can you provide more context or clarify what you are referring to? I'll do my best to help.\n"
     ]
    }
   ],
   "source": [
    "USER_QUESTION = \"What Sam Witteveen is said about llama3.2 in this video?\"\n",
    "print(llm.invoke(USER_QUESTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam Witteveen doesn't mention \"llama3.2\" in this video. However, he does mention that there are models available, including the 3 billion text model and the 1 billion text model, which suggests that there may be a version of Llama called \"Llama 3\" or \"Llama 3.x\", but it's not explicitly stated as \"llama3.2\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SUMMARY_PROMPT = f\"\"\"Answer user questions based on the provided transcript from a youtube video. \\\n",
    "Transcript: ```{transcript}```\n",
    "User question: {USER_QUESTION}\n",
    "\"\"\"\n",
    "\n",
    "print(llm.invoke(SUMMARY_PROMPT))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top takeaways from the video:\n",
      "\n",
      "* Meta has released a set of AI models, including Llama, that can be accessed through Hugging Face.\n",
      "* The models include smaller text models (e.g. 1 billion tokens) and larger models (e.g. 3 billion tokens).\n",
      "* The smaller models are faster and more suitable for tasks like summarization and simple extraction.\n",
      "* The larger models are slower but may be better suited for tasks that require more complex processing, such as fine-tuning for specific use cases.\n",
      "* Fine-tuning these models is expected to become easier due to their small size.\n",
      "* Multimodal models (e.g. SAM2) will also be released, which could lead to interesting combinations with Llama models and other AI technologies.\n",
      "* The release of these models marks a significant step forward for Meta's AI efforts, particularly in the area of multimodal processing.\n",
      "\n",
      "Note that the video does not provide a clear list of \"top takeaways\", but rather presents an overview of the released models and their potential applications.\n"
     ]
    }
   ],
   "source": [
    "USER_QUESTION = \"what are the top takeaways from this video in bullet points?\"\n",
    "\n",
    "SUMMARY_PROMPT = f\"\"\"Answer user questions based on the provided transcript from a youtube video. \\\n",
    "Transcript: ```{transcript}```\n",
    "User question: {USER_QUESTION}\"\"\"\n",
    "\n",
    "print(llm.invoke(SUMMARY_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUESTION = \"what are the top takeaways from this video in bullet points?\"\n",
    "\n",
    "SUMMARY_PROMPT = f\"\"\"Answer user questions based on the provided transcript from a youtube video. \\\n",
    "Transcript: ```{transcript}```\n",
    "User question: {USER_QUESTION}\"\"\"\n",
    "\n",
    "print(llm.invoke(SUMMARY_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oh1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
